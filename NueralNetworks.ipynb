{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMllWhBoiI81G7gzRQucD4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliyarinu/Projects/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMbwiYtfdsCK",
        "outputId": "3a93c2de-0d6b-4d06-fa99-bfd5668d2ecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "a = torch.tensor([1,2,3,4])\n",
        "b = torch.tensor([5,6,7,8])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nRe2O4IOlMf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True) #requiresgrad works only for floats not on integers , this x tensor has required grad facility means pytorch keeps track of every operations involving x\n",
        "y = x.mean()\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQyNc3pFsK9Q",
        "outputId": "37454fdf-fef1-4299-f94f-93fa19a84e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5543, 1.4537, 0.8985], requires_grad=True)\n",
            "tensor(0.9688, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward() # backpropogate from y and calculate the gradient with respect to all the tensors that has requiregrad = true\n",
        "print(x.grad) #gradient of y wrt x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIvSR5dkl3Na",
        "outputId": "8bbcc36b-1b1c-4dfa-af7b-fa51c9881b97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3333, 0.3333, 0.3333])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = (y**2).mean()\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uie_8Ual8Yrt",
        "outputId": "12c6ceb3-0034-4059-bc3c-407c3a186914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9792, 0.9792, 0.9792])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When is retain_graph=True needed?\n",
        "When you do multiple backward passes through the same output that depends on a variable (x)\n",
        "\n",
        "Or when you build a new computation graph from something that still requires gradients and depends on an old graph"
      ],
      "metadata": {
        "id": "2Y8l8Z2tH-z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,requires_grad = True)\n",
        "w = torch.tensor([1,2],dtype=float,requires_grad=True)\n",
        "y = (x*w).sum()\n",
        "y.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTmhLdQz85pj",
        "outputId": "b13fc97a-941b-481f-a64c-227e65a58e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.4749, -1.1422], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2,3)\n",
        "b = (a**2).sum()\n",
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85Cc7apCJklP",
        "outputId": "fcdbb53d-a232-4841-daac-cb2e58b76a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad_(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xieWcdhxPM53",
        "outputId": "4e145f98-a484-412a-8457-1848ce4ac58f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7991, -0.2910,  1.6877],\n",
              "        [ 1.0251, -0.1857, -0.1571]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.detach_()\n",
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiteypV0Pah2",
        "outputId": "d87664e1-fce2-4200-8ea5-1c3ef3cc3551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(2,requires_grad=True)\n",
        "w = torch.randn(2,requires_grad=True)\n",
        "print('before',w)\n",
        "for epoch in range(5):\n",
        "  output = (x*w).sum()\n",
        "  output.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= 0.1*(w.grad) # 3rd method to detach requires_grad\n",
        "  #print(w.grad)\n",
        "  w.grad.zero_()\n",
        "print('after training',w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MvGftiVPgrE",
        "outputId": "8fc9fde6-6b4b-4dc3-e518-f82b37c488df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before tensor([-0.4273, -0.7208], requires_grad=True)\n",
            "after training tensor([ 0.3597, -0.7666], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why gradients accumulate: In PyTorch, unless you call w.grad.zero_() or w.grad = None, gradients are accumulated in .grad.\n",
        "In epoch 1, w.grad becomes del y /del w\n",
        "in epoch 2, w.grad adds another del y /del w and thus 2*del y /del w."
      ],
      "metadata": {
        "id": "OKcz9eWMUzLw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "variables which has requires_grad true cannot have inplace operation.\n",
        "note that detaching is not inplace operation unless it is detach_"
      ],
      "metadata": {
        "id": "6p3KLcNrX9kT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU 3 times faster than cpu, T4 is 3 to 13 times faster than cpu. TPU is faster than gpu and cpu (in deep learning ) bc tpu specifically designed for tensor computaions."
      ],
      "metadata": {
        "id": "pholUjeacpET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CWZGoxuOdlvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06YHZ277rESo",
        "outputId": "c41bb810-86c1-460b-91e3-b9f34013aad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[73,67,43],\n",
        "                   [91,88,64],\n",
        "                   [87,134,58],\n",
        "                   [102,43,37],\n",
        "                   [69,96,70],\n",
        "                   [85,100,60],\n",
        "                   [95,80,55],\n",
        "                   [105,120,75],\n",
        "                   [78,90,50],\n",
        "                   [82, 70, 45]],dtype = 'float32')\n",
        "targets = np.array([[56,70],\n",
        "                    [81,101],\n",
        "                    [119,133],\n",
        "                    [22, 37],\n",
        "                    [103,119],\n",
        "                    [98, 110],\n",
        "                    [88, 95],\n",
        "                    [115, 140],\n",
        "                    [76, 85],\n",
        "                    [65, 75]], dtype = 'float32')"
      ],
      "metadata": {
        "id": "vB2kahIJsC6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_t = torch.from_numpy(inputs)\n",
        "targets_t = torch.from_numpy(targets)\n",
        "print(inputs_t)\n",
        "print(targets_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9fcoofDwU6o",
        "outputId": "4f1abd8e-b8de-4d15-cc7f-2f04083f121b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.],\n",
            "        [ 85., 100.,  60.],\n",
            "        [ 95.,  80.,  55.],\n",
            "        [105., 120.,  75.],\n",
            "        [ 78.,  90.,  50.],\n",
            "        [ 82.,  70.,  45.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 98., 110.],\n",
            "        [ 88.,  95.],\n",
            "        [115., 140.],\n",
            "        [ 76.,  85.],\n",
            "        [ 65.,  75.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "auto grad works only on floats"
      ],
      "metadata": {
        "id": "vfWRISt8yPW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.randn(3,2,requires_grad=True)\n",
        "b = torch.randn(2,requires_grad=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ySUbhmVOwraQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forwardmodel(x):\n",
        "  return torch.matmul(x,w)+b\n",
        "def lossfunction(p,t):\n",
        "  diff = p-t\n",
        "  return torch.sum(diff**2)/ diff.numel()"
      ],
      "metadata": {
        "id": "G2azeNVmNnNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in range(100):\n",
        "  preds = forwardmodel(inputs_t)\n",
        "  loss = lossfunction(preds,targets_t)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= 0.0001*w.grad\n",
        "    b -= 0.0001*b.grad\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "finalvalloss = lossfunction(preds,targets_t)\n",
        "print(finalvalloss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCh6QcQZ9BKN",
        "outputId": "80d08dbe-af2e-4c39-f6ca-bc7193360dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(37.7613, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let us use pytorc hbuiltin functions"
      ],
      "metadata": {
        "id": "UoVtAVa6cHld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset,DataLoader"
      ],
      "metadata": {
        "id": "6FuOfFY5uhDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myfirstNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(3,4)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.layer2 = nn.Linear(4,2)\n",
        "\n",
        "  def forwardpass(self, x):\n",
        "      x = self.layer1(x)\n",
        "      x =  self.act1(x)\n",
        "      x = self.layer2(x)\n",
        "\n",
        "      return x\n",
        "model = myfirstNN()\n",
        "\n",
        "for name,params in model.named_parameters():\n",
        "  print('name',name)\n",
        "  print('param',params)"
      ],
      "metadata": {
        "id": "D8aivAsLbVFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d248be-ba98-4ae0-e0a4-90b9702fe879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name layer1.weight\n",
            "param Parameter containing:\n",
            "tensor([[-0.3439,  0.2241,  0.2803],\n",
            "        [-0.2816,  0.4350,  0.4576],\n",
            "        [ 0.5591,  0.3427,  0.4329],\n",
            "        [ 0.1750, -0.1167, -0.1437]], requires_grad=True)\n",
            "name layer1.bias\n",
            "param Parameter containing:\n",
            "tensor([-0.1781,  0.4994, -0.3607,  0.4391], requires_grad=True)\n",
            "name layer2.weight\n",
            "param Parameter containing:\n",
            "tensor([[ 0.0530,  0.3495,  0.1971,  0.4766],\n",
            "        [-0.0837, -0.0641, -0.3097,  0.0216]], requires_grad=True)\n",
            "name layer2.bias\n",
            "param Parameter containing:\n",
            "tensor([-0.4654,  0.2943], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A more deep nueral network Architecture with 3 hidden layers"
      ],
      "metadata": {
        "id": "awMOpWlJ0tgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "VQ5q61wu0Zy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _3hiddenlayernn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(3,4)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.layerh = nn.Linear(4,4)\n",
        "    self.act2 = nn.LeakyReLU()\n",
        "    self.layer3 = nn.Linear(4,2)\n",
        "\n",
        "  def forwardpass(self,x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.layerh(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.layerh(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.layerh(x)\n",
        "    x = self.layer3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model = _3hiddenlayernn()\n",
        "for name,params in model.named_parameters():\n",
        "  print('name',name)\n",
        "  print('param',params)"
      ],
      "metadata": {
        "id": "1aj5l9-R04rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = torch.nn.L1Loss()\n",
        "opt = torch.optim.Adam(model.parameters(),lr= 0.0001)"
      ],
      "metadata": {
        "id": "LeDekmyJ7OUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingfunc(model,nepoch,lossfunc,optifunc):\n",
        "  for epoch in range(nepoch):\n",
        "\n",
        "    preds=model.forwardpass(inputs_t)\n",
        "    loss = lossfunc(preds,targets_t)\n",
        "    loss.backward()\n",
        "    if epoch%100 == 99:\n",
        "      print(loss)\n",
        "    optifunc.step()                           #with torch.no_grad():\n",
        "                                            #w -= 0.0001*w.grad\n",
        "                                           #b -= 0.0001*b.grad\n",
        "    optifunc.zero_grad()                           #w.grad_zero_\n",
        "\n",
        "trainingfunc(model,1000,mae,opt)\n",
        "#preds = model.forwardpass(inputs_t)\n",
        "                             #b.grad_zero_\n"
      ],
      "metadata": {
        "id": "Dm4_q20CGEU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "hjhdlLHvOPpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class _2hiddenlayer(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.inputlayer1 = nn.Linear(3,4)\n",
        "      self.layer1 = nn.Linear(4,4)\n",
        "      self.layer2 = nn.Linear(4,3)\n",
        "      self.outlayer = nn.Linear(3,2)\n",
        "      self.act1 = nn.LeakyReLU()\n",
        "      self.act2 = nn.ReLU()\n",
        "\n",
        "    def forwardmodel(self,x):\n",
        "      x = self.inputlayer1(x)\n",
        "      x = self.act1(x)\n",
        "      x  = self.layer1(x)\n",
        "      x = self.act1(x)\n",
        "      x = self.layer2(x)\n",
        "      x = self.act2(x)\n",
        "      x = self.outlayer(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "model = _2hiddenlayer()\n",
        "\n",
        "for name,params in model.named_parameters():\n",
        "  print('nmae',name)\n",
        "  print('param',params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fiz1Cb9XOSui",
        "outputId": "7e4db3dd-ecac-45c5-b450-e88668934655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nmae inputlayer1.weight\n",
            "param Parameter containing:\n",
            "tensor([[ 0.0558, -0.3018,  0.3113],\n",
            "        [-0.2231, -0.5743,  0.4812],\n",
            "        [-0.1040,  0.0879, -0.0441],\n",
            "        [-0.1627, -0.0967,  0.4752]], requires_grad=True)\n",
            "nmae inputlayer1.bias\n",
            "param Parameter containing:\n",
            "tensor([-0.2544, -0.1602,  0.0029, -0.0783], requires_grad=True)\n",
            "nmae layer1.weight\n",
            "param Parameter containing:\n",
            "tensor([[-0.3220,  0.3529, -0.2204,  0.4977],\n",
            "        [ 0.1437,  0.2874, -0.1607, -0.2368],\n",
            "        [-0.4475, -0.3788,  0.3204, -0.4577],\n",
            "        [-0.3265,  0.1216,  0.2641,  0.4761]], requires_grad=True)\n",
            "nmae layer1.bias\n",
            "param Parameter containing:\n",
            "tensor([ 0.0778,  0.0087, -0.0873, -0.3602], requires_grad=True)\n",
            "nmae layer2.weight\n",
            "param Parameter containing:\n",
            "tensor([[-0.0751,  0.2158, -0.2338, -0.2606],\n",
            "        [ 0.2692,  0.1880, -0.3440, -0.4045],\n",
            "        [-0.4826, -0.1476,  0.4362, -0.3760]], requires_grad=True)\n",
            "nmae layer2.bias\n",
            "param Parameter containing:\n",
            "tensor([-0.3492,  0.0214,  0.3525], requires_grad=True)\n",
            "nmae outlayer.weight\n",
            "param Parameter containing:\n",
            "tensor([[ 0.0572,  0.5133,  0.4950],\n",
            "        [-0.4836, -0.3049,  0.5653]], requires_grad=True)\n",
            "nmae outlayer.bias\n",
            "param Parameter containing:\n",
            "tensor([-0.0474,  0.1832], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trained(n,model,lossfun,opt):\n",
        "  for i in range(n):\n",
        "    preds = model(inputs_t)\n",
        "    loss = lossfun(preds,targets_t)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "    if i%100 == 99:\n",
        "      print(loss)\n",
        "lossf = torch.nn.L1Loss()\n",
        "opt = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
        "trained(1000,model.forwardmodel,lossf,opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGrq3oeoR9Em",
        "outputId": "54c1a37e-d20a-4cdb-fd2d-2c080a08523d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(84.4681, grad_fn=<MeanBackward0>)\n",
            "tensor(57.7109, grad_fn=<MeanBackward0>)\n",
            "tensor(10.8637, grad_fn=<MeanBackward0>)\n",
            "tensor(10.3972, grad_fn=<MeanBackward0>)\n",
            "tensor(9.9478, grad_fn=<MeanBackward0>)\n",
            "tensor(9.4184, grad_fn=<MeanBackward0>)\n",
            "tensor(8.8067, grad_fn=<MeanBackward0>)\n",
            "tensor(8.1003, grad_fn=<MeanBackward0>)\n",
            "tensor(7.5248, grad_fn=<MeanBackward0>)\n",
            "tensor(6.9410, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "FpIoG_zGj2mI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_ds = TensorDataset(inputs_t,targets_t)\n",
        "data_dl = DataLoader(data_ds, batch_size=5, shuffle=True)"
      ],
      "metadata": {
        "id": "l3-s4MRHkUN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class delet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(3,4)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.l2 = nn.Linear(4,4)\n",
        "    self.l3 = nn.Linear(4,2)\n",
        "  def fwd(self,x):\n",
        "    x = self.l1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.l2(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.l3(x)\n",
        "\n",
        "    return x\n",
        "m = delet()\n",
        "for name,params in m.named_parameters():\n",
        "    print(name)\n",
        "    print(params)\n"
      ],
      "metadata": {
        "id": "TFlJc5SGmqgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingfunction(model,nepochs,lossf,opt):\n",
        "  for e in range(nepochs):\n",
        "    for xb, tb in data_dl:\n",
        "      preds = model(xb)\n",
        "      loss = lossf(preds,tb)\n",
        "      loss.backward()\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "    if e%100 == 99:\n",
        "      print(loss)\n",
        "lossfunction = torch.nn.L1Loss()\n",
        "opt = torch.optim.SGD(m.parameters(), lr = 0.001)\n",
        "\n",
        "trainingfunction(m.fwd,1000,lossfunction,opt)\n"
      ],
      "metadata": {
        "id": "cmMHlYw8xjr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'"
      ],
      "metadata": {
        "id": "gqUArha233C_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the iris NN"
      ],
      "metadata": {
        "id": "nQEMclCX8nVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "WQCKPM-Q8V85"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "irisdata = pd.read_csv('https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv')"
      ],
      "metadata": {
        "id": "6_kZHZtu8sN4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "irisdata.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7Agbb518-af",
        "outputId": "fc2537ce-18fa-4d2f-aea1-1e7ef40ef11b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
              "       'species'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = irisdata.drop(columns=['species'])\n",
        "data = data.values\n",
        "data = torch.tensor(data,dtype = torch.float32)\n",
        "irisdata['species'] = irisdata['species'].replace('setosa',0)\n",
        "irisdata['species'] = irisdata['species'].replace('versicolor',1)\n",
        "irisdata['species'] = irisdata['species'].replace('virginica',2)\n",
        "\n",
        "\n",
        "inputfts = data\n",
        "\n",
        "t = irisdata['species'].values\n",
        "targetsarr = np.zeros((len(t),3))\n",
        "for i in range(len(t)):\n",
        "  if t[i] == 0:\n",
        "    targetsarr[i,0] = 1\n",
        "    targetsarr[i,1] = 0\n",
        "    targetsarr[i,2] = 0\n",
        "  if t[i] == 1:\n",
        "    targetsarr[i,0] = 0\n",
        "    targetsarr[i,1] = 1\n",
        "    targetsarr[i,2] = 0\n",
        "  if t[i] == 2:\n",
        "    targetsarr[i,0] = 0\n",
        "    targetsarr[i,1] = 0\n",
        "    targetsarr[i,2] = 1\n"
      ],
      "metadata": {
        "id": "M2oz4oun_TBj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dce0f52-5f95-44dd-b4af-17c3402aebe2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-451f65a99ff6>:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  irisdata['species'] = irisdata['species'].replace('virginica',2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splt dataset to train-test data"
      ],
      "metadata": {
        "id": "Qo0PP6EASTUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datanew = irisdata.drop(columns = ['species']).values\n",
        "\n",
        "targnew = irisdata['species'].values\n",
        "X_train,X_test,y_train,y_test = train_test_split(datanew,targnew,test_size=0.2,random_state=42)\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "y_train = torch.FloatTensor(y_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "y_test = torch.FloatTensor(y_test)"
      ],
      "metadata": {
        "id": "kT7ALQWbSa2b"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader,TensorDataset"
      ],
      "metadata": {
        "id": "Ug27fuMAsGJs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(X_train,y_train)\n",
        "train_dl = DataLoader(train_ds,batch_size=24,shuffle = True)"
      ],
      "metadata": {
        "id": "srpUxEsqsPJb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class irisnn(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.inputlayer = nn.Linear(4,6)\n",
        "    self.layer1 = nn.Linear(6,6)\n",
        "    self.layer2 = nn.Linear(6,4)\n",
        "    self.outlayer = nn.Linear(4,3)\n",
        "    self.act = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    x = self.inputlayer(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.act(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.act(x)\n",
        "    x = self.outlayer(x)\n",
        "    return x\n",
        "\n",
        "model = irisnn()\n",
        "for name,params in model.named_parameters():\n",
        "  print(name)\n",
        "  print(params)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq-29Z3K_WrC",
        "outputId": "133f332a-faaf-4975-a4d7-649ffaff897c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputlayer.weight\n",
            "Parameter containing:\n",
            "tensor([[ 0.3665, -0.0431,  0.4657,  0.1859],\n",
            "        [ 0.2550, -0.2779,  0.3117, -0.1121],\n",
            "        [-0.3786,  0.3806,  0.2547,  0.1129],\n",
            "        [-0.2165, -0.3952, -0.1512, -0.4273],\n",
            "        [ 0.0934,  0.1569,  0.2902, -0.2182],\n",
            "        [ 0.4788, -0.3032,  0.4741,  0.3204]], requires_grad=True)\n",
            "inputlayer.bias\n",
            "Parameter containing:\n",
            "tensor([-0.2009,  0.0648,  0.3234,  0.0831,  0.2699,  0.0330],\n",
            "       requires_grad=True)\n",
            "layer1.weight\n",
            "Parameter containing:\n",
            "tensor([[ 0.1079, -0.1365,  0.0751, -0.0283,  0.1920,  0.3591],\n",
            "        [-0.1489,  0.1000,  0.0009,  0.3004,  0.0081, -0.2539],\n",
            "        [-0.2155,  0.0950, -0.0807,  0.2147, -0.2194, -0.0500],\n",
            "        [-0.1875, -0.0427, -0.1902, -0.3719,  0.0174, -0.2105],\n",
            "        [ 0.3778, -0.1620,  0.0064, -0.2450, -0.1556,  0.3611],\n",
            "        [ 0.0477,  0.3838, -0.3520, -0.0748, -0.3991,  0.0044]],\n",
            "       requires_grad=True)\n",
            "layer1.bias\n",
            "Parameter containing:\n",
            "tensor([ 0.0186,  0.2425,  0.0708, -0.0223,  0.1391, -0.2322],\n",
            "       requires_grad=True)\n",
            "layer2.weight\n",
            "Parameter containing:\n",
            "tensor([[ 0.2863,  0.2492,  0.0142,  0.1877,  0.3955,  0.1507],\n",
            "        [ 0.0716,  0.2830, -0.3152,  0.1947, -0.2104,  0.2628],\n",
            "        [-0.3594,  0.2428,  0.1063,  0.1322, -0.2236,  0.2648],\n",
            "        [-0.0716, -0.2301, -0.1518, -0.3774,  0.3270, -0.0240]],\n",
            "       requires_grad=True)\n",
            "layer2.bias\n",
            "Parameter containing:\n",
            "tensor([-0.3501, -0.2127, -0.2963,  0.2629], requires_grad=True)\n",
            "outlayer.weight\n",
            "Parameter containing:\n",
            "tensor([[ 0.3212, -0.4155,  0.2329, -0.3378],\n",
            "        [ 0.2561,  0.1537,  0.0791, -0.0524],\n",
            "        [ 0.3680, -0.2112,  0.3764, -0.3681]], requires_grad=True)\n",
            "outlayer.bias\n",
            "Parameter containing:\n",
            "tensor([-0.4694,  0.4124,  0.0048], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def trainiris(nepochs,model,lossfunc,optimizing,train_dl):\n",
        "  lossvals =[]\n",
        "  for e in range(nepochs):\n",
        "    for xb,yb in (train_dl):\n",
        "      preds = model(xb)\n",
        "      loss = lossfunc(preds,yb)\n",
        "      loss.backward()\n",
        "      optimizing.step()\n",
        "      optimizing.zero_grad()\n",
        "      val = loss.item()\n",
        "    lossvals.append(val)\n",
        "  return lossvals\n",
        "lossfun = torch.nn.CrossEntropyLoss()\n",
        "opti = torch.optim.SGD(model.parameters(),lr = 0.001)\n",
        "listvals = trainiris(1000,model,lossfun,opti,train_dl)\n",
        "print(listvals)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDMIbRLPNKgk",
        "outputId": "6de67c6d-3e33-4d84-e695-dee347c739ff"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0436735153198242, 1.0458029508590698, 1.067492127418518, 1.061726450920105, 1.0773861408233643, 1.0563832521438599, 1.0603787899017334, 1.0642188787460327, 1.047663927078247, 1.0764219760894775, 1.0690749883651733, 1.0531173944473267, 1.0454281568527222, 1.02940034866333, 1.077222466468811, 1.0714370012283325, 1.033103108406067, 1.0646897554397583, 1.0639113187789917, 1.038358211517334, 1.0589879751205444, 1.0663782358169556, 1.0712839365005493, 1.0761117935180664, 1.0491058826446533, 1.0535216331481934, 1.0542622804641724, 1.068058729171753, 1.0755189657211304, 1.0314611196517944, 1.0817443132400513, 1.096291422843933, 1.0453977584838867, 1.0322401523590088, 1.0693000555038452, 1.0202760696411133, 1.0706841945648193, 1.050638198852539, 1.0645359754562378, 1.048056721687317, 1.0752402544021606, 1.067304015159607, 1.0326911211013794, 1.0723299980163574, 1.0478341579437256, 1.0083987712860107, 1.0539872646331787, 1.0606666803359985, 1.019250512123108, 1.0440629720687866, 1.0209707021713257, 1.1062217950820923, 1.022596001625061, 1.0423940420150757, 1.025396466255188, 1.0414890050888062, 1.0775822401046753, 1.0767778158187866, 1.0746710300445557, 1.0445516109466553, 1.0306700468063354, 1.061342716217041, 1.0595452785491943, 1.0734670162200928, 1.0549894571304321, 1.036375880241394, 1.0461629629135132, 1.025900959968567, 1.0487799644470215, 1.096731424331665, 1.0557293891906738, 1.0749136209487915, 1.061819076538086, 1.0127280950546265, 1.0443485975265503, 1.0202780961990356, 1.0086498260498047, 1.0603586435317993, 1.0555497407913208, 1.079336166381836, 1.0270267724990845, 1.0923150777816772, 1.0377554893493652, 1.00076425075531, 1.0265607833862305, 1.0366145372390747, 1.017816424369812, 1.047817349433899, 1.0490933656692505, 1.045802116394043, 1.0212675333023071, 1.088236689567566, 1.042734146118164, 1.0196317434310913, 1.0211588144302368, 1.078685998916626, 1.0451399087905884, 1.0329022407531738, 1.1064523458480835, 1.058186650276184, 1.063860535621643, 1.0420857667922974, 1.0562323331832886, 0.9934037327766418, 1.0386369228363037, 1.0440534353256226, 1.062261700630188, 1.0564111471176147, 1.0227426290512085, 1.0324212312698364, 1.003137469291687, 1.0188370943069458, 1.0412307977676392, 1.0168557167053223, 1.011534571647644, 1.0817339420318604, 1.0570762157440186, 1.0477033853530884, 1.0134221315383911, 1.0954784154891968, 1.0434938669204712, 1.0893267393112183, 1.0692094564437866, 1.0838968753814697, 1.0568331480026245, 1.0313903093338013, 1.0566730499267578, 1.0494049787521362, 0.9721450209617615, 0.9946372509002686, 1.0822181701660156, 1.0491294860839844, 1.054073691368103, 1.057379961013794, 1.0285741090774536, 1.0851415395736694, 1.0504274368286133, 1.0292736291885376, 1.0378955602645874, 1.0260354280471802, 1.0202380418777466, 1.0430327653884888, 1.05380380153656, 1.0043607950210571, 1.0739854574203491, 1.0773122310638428, 1.0560063123703003, 1.0645934343338013, 1.068691372871399, 1.0140570402145386, 1.029502511024475, 0.9956352114677429, 0.9778712391853333, 0.9988254904747009, 1.0376282930374146, 1.076825499534607, 1.0819720029830933, 1.0187424421310425, 1.0293031930923462, 1.0511178970336914, 1.0158675909042358, 1.020574927330017, 1.0002340078353882, 1.0096720457077026, 1.0380223989486694, 1.0152932405471802, 1.06694757938385, 1.027842402458191, 1.0762192010879517, 1.053543210029602, 1.0398513078689575, 1.0015169382095337, 1.0030430555343628, 1.0522481203079224, 1.0288410186767578, 1.0478650331497192, 1.0554746389389038, 1.0416852235794067, 1.0414713621139526, 1.0625249147415161, 1.0389169454574585, 1.0712987184524536, 1.038294792175293, 1.0167981386184692, 1.0242762565612793, 1.0790563821792603, 1.0210126638412476, 1.017627477645874, 1.0509603023529053, 1.034383773803711, 0.9988486766815186, 1.0462692975997925, 1.0045188665390015, 1.0710391998291016, 1.033278226852417, 1.0639452934265137, 0.9788113236427307, 1.0306885242462158, 1.026281476020813, 1.0939794778823853, 0.9614353775978088, 1.0576707124710083, 1.0324786901474, 1.0570917129516602, 1.0790499448776245, 1.0045305490493774, 1.0452481508255005, 1.0512617826461792, 1.0999631881713867, 1.0254484415054321, 1.019610047340393, 1.0252491235733032, 1.0575231313705444, 1.0678950548171997, 1.00540292263031, 0.9493237137794495, 1.0626814365386963, 1.0556906461715698, 1.0480669736862183, 0.949627697467804, 0.9393690228462219, 1.0274590253829956, 1.0588635206222534, 0.9893013834953308, 1.0278129577636719, 0.9943404197692871, 0.9606699347496033, 0.9575870633125305, 0.9537647366523743, 1.0066334009170532, 1.0345975160598755, 1.1017138957977295, 1.0493834018707275, 1.007632851600647, 1.0026766061782837, 0.9872494339942932, 1.0312857627868652, 1.014868140220642, 1.0469152927398682, 1.0314470529556274, 1.033033013343811, 1.0345877408981323, 1.0406111478805542, 1.0507248640060425, 0.9918670058250427, 1.0723310708999634, 1.0626683235168457, 1.0792030096054077, 1.02569580078125, 1.0136747360229492, 0.9983305335044861, 1.015173316001892, 1.0116875171661377, 1.0470894575119019, 1.027023434638977, 1.0446099042892456, 1.007581114768982, 0.9740038514137268, 1.0303492546081543, 1.0214534997940063, 1.0207066535949707, 1.05305016040802, 0.99587482213974, 0.9973939061164856, 1.021600604057312, 1.0406314134597778, 0.9634037613868713, 0.949350118637085, 1.0468798875808716, 0.9881435036659241, 0.9943530559539795, 1.0459755659103394, 0.9959518313407898, 0.9658483862876892, 1.0217922925949097, 1.0748380422592163, 0.9726665019989014, 1.0955320596694946, 1.0351094007492065, 1.0406755208969116, 1.0639537572860718, 0.9891412854194641, 1.0838290452957153, 0.9504278302192688, 1.007759690284729, 1.0640335083007812, 1.046904444694519, 0.9600250124931335, 1.0814355611801147, 1.041154146194458, 1.0471389293670654, 1.0222376585006714, 1.0937309265136719, 1.0218642950057983, 1.0345414876937866, 1.0056308507919312, 1.0215322971343994, 0.9720444083213806, 0.923647403717041, 1.0047917366027832, 1.0107074975967407, 0.9613213539123535, 1.015992522239685, 1.0268661975860596, 0.9753296971321106, 1.0103100538253784, 0.9966137409210205, 0.9713404774665833, 0.9802803993225098, 0.91876220703125, 1.0311353206634521, 1.042688012123108, 1.0036674737930298, 1.0326210260391235, 1.0325647592544556, 1.0847140550613403, 0.9847763180732727, 0.9325889945030212, 0.9863379597663879, 0.9846881031990051, 1.0222105979919434, 0.9872534275054932, 1.0446144342422485, 1.032543420791626, 1.0467380285263062, 1.0666812658309937, 1.0040371417999268, 1.0725351572036743, 1.028992772102356, 1.038382649421692, 0.9833686947822571, 0.9887290596961975, 1.0139998197555542, 0.976871907711029, 1.0056596994400024, 1.0400919914245605, 1.0288619995117188, 0.9865363240242004, 0.997053861618042, 1.0288856029510498, 0.9972551465034485, 1.0167059898376465, 1.0177541971206665, 1.0785783529281616, 0.9885444045066833, 0.9869992136955261, 1.0779738426208496, 1.0529776811599731, 1.0356959104537964, 0.9786677956581116, 0.9621050357818604, 0.9581521153450012, 1.0404092073440552, 1.0677638053894043, 0.9365035891532898, 1.0585821866989136, 1.0352853536605835, 1.0263715982437134, 0.9898615479469299, 1.015459656715393, 0.9684803485870361, 1.0152884721755981, 1.0087939500808716, 0.981813371181488, 0.9822251200675964, 0.9989396929740906, 0.9202540516853333, 1.011942982673645, 0.9974157214164734, 1.0176219940185547, 0.987717866897583, 0.9428133368492126, 1.0309898853302002, 1.0388894081115723, 1.0463330745697021, 1.0245013236999512, 1.0240815877914429, 0.9832499623298645, 1.057499885559082, 0.9886777997016907, 1.0335689783096313, 1.0461735725402832, 0.9841633439064026, 1.0535403490066528, 0.9737081527709961, 0.9552974104881287, 0.9486851692199707, 0.9560399055480957, 1.0065592527389526, 0.9609996676445007, 1.0133055448532104, 0.9711349010467529, 0.9807586073875427, 0.9759102463722229, 0.9404647946357727, 1.0211786031723022, 0.9768803715705872, 0.9431937336921692, 0.9823107719421387, 1.0024274587631226, 1.0363861322402954, 0.9725451469421387, 0.9801339507102966, 1.0483039617538452, 1.0202597379684448, 0.980658233165741, 1.002090334892273, 1.0074687004089355, 0.9806343913078308, 0.9634194374084473, 1.012255311012268, 0.9678327441215515, 1.0329136848449707, 0.964617908000946, 0.9342694878578186, 0.9486217498779297, 0.9625858664512634, 0.997382640838623, 1.0143238306045532, 0.9845883250236511, 0.9248102307319641, 1.0113632678985596, 0.965639591217041, 1.0001918077468872, 0.9945366978645325, 0.982840359210968, 0.9277723431587219, 1.0403145551681519, 0.9464235305786133, 0.9900600910186768, 0.9534252285957336, 0.9954075813293457, 1.0072044134140015, 1.037468671798706, 0.962393581867218, 0.9705936908721924, 1.0065288543701172, 0.9330123066902161, 1.0021501779556274, 1.0178896188735962, 0.9148091673851013, 0.9947659969329834, 0.979196310043335, 0.9961133003234863, 0.9649160504341125, 1.0026330947875977, 1.023300290107727, 0.884904682636261, 0.9697940945625305, 0.9632888436317444, 0.9777862429618835, 0.9428507685661316, 0.9826996326446533, 1.0098307132720947, 0.997140109539032, 1.0333242416381836, 0.9168519377708435, 1.0388139486312866, 1.0131916999816895, 0.9795000553131104, 0.9754131436347961, 0.9193980097770691, 1.0136756896972656, 1.0477598905563354, 0.9015665054321289, 0.9793397784233093, 0.9838834404945374, 0.9279016852378845, 0.9538297653198242, 0.9811328053474426, 1.0024117231369019, 1.0181485414505005, 1.0182913541793823, 0.9743930697441101, 0.998336136341095, 1.0127843618392944, 0.963561475276947, 1.007059931755066, 0.9724175333976746, 0.9621210098266602, 0.9428578019142151, 1.0052903890609741, 1.0037416219711304, 0.9400383830070496, 0.9672505259513855, 1.0050976276397705, 0.958384096622467, 1.012847661972046, 0.9696764349937439, 0.9859721064567566, 0.9480524063110352, 0.9578292369842529, 0.9061087965965271, 1.005435824394226, 1.0051217079162598, 1.003991723060608, 0.9241333603858948, 0.9835584759712219, 0.9667136073112488, 0.9772501587867737, 0.8954648375511169, 1.0353684425354004, 0.9503325819969177, 0.9996553063392639, 0.9791412353515625, 0.9675888419151306, 0.9540017247200012, 0.9854039549827576, 1.0219473838806152, 0.9878954887390137, 0.9487479329109192, 0.9310271143913269, 0.9219610691070557, 0.9442284107208252, 0.9580936431884766, 0.9776152968406677, 0.9447622895240784, 0.9544019103050232, 0.9374299645423889, 0.921920120716095, 0.9301288723945618, 0.9445499777793884, 1.0143897533416748, 0.9776158928871155, 0.9328784942626953, 1.0115323066711426, 0.9363005757331848, 0.9395472407341003, 0.9081031680107117, 0.9374416470527649, 0.9963266253471375, 0.9785366654396057, 0.9721667170524597, 0.9961448311805725, 1.0202518701553345, 0.9129512906074524, 0.9767683148384094, 0.9610080122947693, 0.9649483561515808, 1.0010817050933838, 0.9735177159309387, 0.9778657555580139, 0.974973738193512, 0.9760931134223938, 0.8969259858131409, 0.9356282353401184, 0.9453387260437012, 0.9624834060668945, 0.9148990511894226, 0.9929256439208984, 1.0062603950500488, 0.9881830811500549, 0.9246122241020203, 0.9347909092903137, 0.953890323638916, 0.9572177529335022, 0.940047562122345, 0.982347309589386, 0.9188997745513916, 0.9600603580474854, 0.9684706330299377, 0.9414091110229492, 0.9495344758033752, 0.8881175518035889, 0.9773032665252686, 1.0048507452011108, 0.9115937352180481, 0.9738286137580872, 0.9176358580589294, 0.9198526740074158, 0.9460828900337219, 0.9859337210655212, 0.9016692638397217, 0.9516785740852356, 0.9164717197418213, 0.9411675930023193, 0.8938420414924622, 0.9746460318565369, 0.9666714668273926, 0.9420707821846008, 0.9651486873626709, 0.9770681262016296, 0.9319384098052979, 0.943225085735321, 0.9338255524635315, 0.9021080136299133, 0.9851253032684326, 0.950063169002533, 0.9375011324882507, 0.8604428172111511, 0.9100627899169922, 0.9105138778686523, 0.8928520083427429, 0.9847726225852966, 0.9009213447570801, 0.9614145159721375, 0.9617257118225098, 0.8864037990570068, 0.969919741153717, 0.9304883480072021, 0.9620363712310791, 0.8684147000312805, 0.9265590310096741, 0.9719787240028381, 0.941677987575531, 0.9605802893638611, 0.9918234944343567, 0.9488434791564941, 0.9653690457344055, 0.9638230800628662, 0.9373727440834045, 0.9544526934623718, 0.97230464220047, 0.9324696063995361, 0.8719117045402527, 0.9065957069396973, 0.9434003829956055, 0.9376208782196045, 0.941183865070343, 0.9526746869087219, 0.9175498485565186, 0.8856166005134583, 0.9222843050956726, 0.9075667262077332, 0.8782369494438171, 0.894658088684082, 0.8930560946464539, 0.9007899165153503, 0.9501299858093262, 0.9201269745826721, 0.9300674796104431, 0.9014558792114258, 0.935309886932373, 0.9274535179138184, 0.8530111312866211, 0.9142191410064697, 0.9406623840332031, 0.9604041576385498, 0.8720674514770508, 0.9311812520027161, 0.8863260746002197, 0.90484619140625, 0.858212411403656, 0.935605525970459, 0.9243326187133789, 0.9440176486968994, 0.9264859557151794, 0.9396113753318787, 0.9326929450035095, 0.8948877453804016, 0.9031264185905457, 0.9230244755744934, 0.8799555897712708, 0.9005746841430664, 0.9242566227912903, 0.8894012570381165, 0.9144008159637451, 0.8971516489982605, 0.9372538924217224, 0.9029219746589661, 0.9257397055625916, 0.8925530314445496, 0.8289124965667725, 0.890439510345459, 0.9228169322013855, 0.8974015116691589, 0.91175776720047, 0.8907580375671387, 0.9041748046875, 0.8675763607025146, 0.9321949481964111, 0.9201710820198059, 0.8913375735282898, 0.9320184588432312, 0.8655059337615967, 0.9149006009101868, 0.8670909404754639, 0.9405279159545898, 0.8402770161628723, 0.8476898074150085, 0.8871849179267883, 0.8583356738090515, 0.8252092003822327, 0.905920684337616, 0.910695493221283, 0.871762216091156, 0.8900933861732483, 0.878548800945282, 0.855818510055542, 0.9232417941093445, 0.8683457970619202, 0.9358997344970703, 0.8081105351448059, 0.8865277767181396, 0.923898458480835, 0.9323499798774719, 0.8860768675804138, 0.8695732951164246, 0.8859413266181946, 0.919917106628418, 0.8972095847129822, 0.8350376486778259, 0.9084798693656921, 0.8865001201629639, 0.9008581638336182, 0.8846640586853027, 0.8059882521629333, 0.8991652131080627, 0.8592172265052795, 0.885004460811615, 0.8544414639472961, 0.8637507557868958, 0.8645018935203552, 0.8708775639533997, 0.9334952235221863, 0.8981866836547852, 0.852185070514679, 0.837923526763916, 0.8496219515800476, 0.8925498127937317, 0.8617416024208069, 0.9197545647621155, 0.8928000926971436, 0.877018392086029, 0.8928982615470886, 0.831367015838623, 0.8891589641571045, 0.893197238445282, 0.8654105067253113, 0.8970540165901184, 0.8645821213722229, 0.8264811635017395, 0.8781716823577881, 0.8662607073783875, 0.8444319367408752, 0.8390706181526184, 0.8293030858039856, 0.8508549332618713, 0.8722588419914246, 0.8558513522148132, 0.8389526009559631, 0.8497621417045593, 0.8539809584617615, 0.8198575377464294, 0.884783923625946, 0.8458806872367859, 0.867309033870697, 0.8704533576965332, 0.8232378959655762, 0.8512275815010071, 0.8032998442649841, 0.8559281229972839, 0.8504069447517395, 0.8177507519721985, 0.8112926483154297, 0.8442142605781555, 0.8721432685852051, 0.8507596850395203, 0.826005756855011, 0.8839914202690125, 0.848247230052948, 0.8457935452461243, 0.8029194474220276, 0.8263362050056458, 0.8449731469154358, 0.8700649738311768, 0.8045483231544495, 0.8129059672355652, 0.8518111705780029, 0.8419206738471985, 0.8411247730255127, 0.8304232954978943, 0.8025131225585938, 0.8430799841880798, 0.8955948948860168, 0.8463801741600037, 0.851985514163971, 0.8136573433876038, 0.825038731098175, 0.8310607075691223, 0.8487392067909241, 0.8768725395202637, 0.854449450969696, 0.8250765800476074, 0.8220770359039307, 0.8373957276344299, 0.8011691570281982, 0.8070476055145264, 0.7468129992485046, 0.7775619626045227, 0.8285492062568665, 0.771038830280304, 0.8677096366882324, 0.794548511505127, 0.8143315315246582, 0.8202210068702698, 0.808454692363739, 0.8258071541786194, 0.8379826545715332, 0.8470533490180969, 0.8348081707954407, 0.8070722222328186, 0.8182689547538757, 0.7994347214698792, 0.8211738467216492, 0.7474040389060974, 0.8032738566398621, 0.8244425654411316, 0.7459848523139954, 0.8359577059745789, 0.8184180855751038, 0.7910923957824707, 0.8230931758880615, 0.8182203769683838, 0.7945063710212708, 0.7736759781837463, 0.8286886811256409, 0.807115375995636, 0.8144772052764893, 0.7725426554679871, 0.8133246898651123, 0.8358988761901855, 0.7560866475105286, 0.7808594703674316, 0.7691061496734619, 0.8002386689186096, 0.7613314986228943, 0.8048057556152344, 0.8364887237548828, 0.7970640659332275, 0.8415767550468445, 0.8020220398902893, 0.8170701861381531, 0.7912247776985168, 0.8020007610321045, 0.7604987025260925, 0.8064975738525391, 0.7535364031791687, 0.7894036769866943, 0.7446555495262146, 0.8027227520942688, 0.8245642781257629, 0.7442488670349121, 0.8135780692100525, 0.8093423247337341, 0.7725121378898621, 0.7621443271636963, 0.761326789855957, 0.8365297913551331, 0.7477097511291504, 0.7363279461860657, 0.7755953669548035, 0.7608596682548523, 0.754810631275177, 0.7584177851676941, 0.7909393310546875, 0.7597160339355469, 0.7393765449523926, 0.7599149346351624, 0.7677449584007263, 0.7666156888008118, 0.7703127861022949, 0.7449856400489807, 0.7671868205070496, 0.7752781510353088, 0.7082158923149109, 0.7618386149406433, 0.7773557305335999, 0.7717568278312683, 0.7617972493171692, 0.7272976040840149, 0.8362255096435547, 0.7321012616157532, 0.7255643010139465, 0.7429834008216858, 0.7405142784118652, 0.7258245348930359, 0.7168521881103516, 0.8016034960746765, 0.8010993599891663, 0.750225305557251, 0.7726154327392578, 0.748145580291748, 0.7827551960945129, 0.7770261764526367, 0.7325404286384583, 0.7838638424873352, 0.8112189769744873, 0.8172898888587952, 0.8047145009040833, 0.6888352036476135, 0.7300853133201599, 0.7102053761482239, 0.7680919766426086, 0.7027366757392883, 0.8207957148551941, 0.7602941989898682, 0.7571480870246887, 0.7367048263549805, 0.7211036682128906, 0.748426616191864, 0.7552042007446289, 0.795079231262207, 0.6902843117713928, 0.7512052655220032, 0.7239039540290833, 0.7256584167480469, 0.6886631846427917, 0.7214622497558594, 0.7165451645851135, 0.7042310833930969, 0.7755796909332275, 0.7793713212013245, 0.7847849726676941, 0.7750911712646484, 0.7392500042915344, 0.7878149151802063, 0.6985249519348145, 0.7121665477752686, 0.7484970092773438, 0.8218212127685547, 0.7754690051078796, 0.7677018046379089, 0.7427510619163513, 0.7338702082633972, 0.8036422729492188, 0.7617505192756653, 0.7386021614074707, 0.7415266036987305, 0.7515532970428467, 0.7557775378227234, 0.70087069272995, 0.6998314261436462, 0.761756420135498, 0.7915200591087341, 0.7299208045005798, 0.7404789328575134, 0.6912481188774109, 0.6683856844902039, 0.7329602241516113, 0.6762312054634094, 0.7334443926811218, 0.7304770350456238, 0.7553752064704895, 0.740956723690033, 0.7325723171234131, 0.7716891169548035, 0.7176287770271301, 0.7088610529899597, 0.7303560376167297, 0.6880069375038147, 0.7351341843605042, 0.6901219487190247, 0.6593217849731445, 0.6826572418212891, 0.720911979675293, 0.7258222699165344, 0.7026663422584534, 0.7383139729499817, 0.7284319996833801, 0.7341153621673584, 0.7124074101448059, 0.7136698365211487, 0.7036290168762207, 0.7146192193031311, 0.6846873164176941, 0.7124223113059998, 0.6877480149269104, 0.717541515827179, 0.7344331741333008, 0.7304463982582092, 0.7226011753082275, 0.6928800940513611, 0.6837663650512695, 0.7082176208496094, 0.7366170287132263, 0.6791427731513977, 0.7077475190162659, 0.7798944115638733, 0.6910935044288635, 0.6747507452964783, 0.6851560473442078, 0.6667609214782715, 0.7057349681854248, 0.6856055855751038, 0.6692585349082947, 0.7163369655609131, 0.7152957916259766, 0.6976631283760071, 0.6881365776062012, 0.7304363250732422, 0.65024334192276, 0.739005982875824, 0.7088598608970642, 0.699492871761322, 0.687691867351532, 0.7054508328437805, 0.7031870484352112, 0.7134503722190857, 0.6955399513244629]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "n = list(range(1000))\n",
        "plt.plot(n,listvals)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('error')\n",
        "plt.grid()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "34TaC-BHdImT",
        "outputId": "d0750a31-d245-4112-8f03-7b1ae8c19b14"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing data"
      ],
      "metadata": {
        "id": "W3JupAHBf2OP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def testiris(model,lossfunc):\n",
        "\n",
        "    preds = model(X_test)\n",
        "    loss = lossfunc(preds,y_test)\n",
        "\n",
        "    return loss.item(),preds\n",
        "lossfun = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "listvals,preds = testiris(model,lossfun)\n",
        "\n",
        "indices = torch.argmax(preds,dim=1)\n",
        "labels ={0:'setosa',1:'versicolor',2:'vergenica'}\n",
        "for i in range(indices.numel()):\n",
        "  print(labels[indices[i].item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IyDdt90jejx",
        "outputId": "70451473-7ece-450a-b593-ae9e029d24fa"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vergenica\n",
            "setosa\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "setosa\n",
            "versicolor\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "setosa\n",
            "setosa\n",
            "setosa\n",
            "setosa\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "setosa\n",
            "vergenica\n",
            "setosa\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "vergenica\n",
            "setosa\n",
            "setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'preds':indices.numpy(),'labels':y_test.numpy()})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "1uGTTuf3yMBy",
        "outputId": "8b159b44-c03f-4180-885b-bf01e1f66a00"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    preds  labels\n",
              "0       2     1.0\n",
              "1       0     0.0\n",
              "2       2     2.0\n",
              "3       2     1.0\n",
              "4       2     1.0\n",
              "5       0     0.0\n",
              "6       1     1.0\n",
              "7       2     2.0\n",
              "8       2     1.0\n",
              "9       2     1.0\n",
              "10      2     2.0\n",
              "11      0     0.0\n",
              "12      0     0.0\n",
              "13      0     0.0\n",
              "14      0     0.0\n",
              "15      2     1.0\n",
              "16      2     2.0\n",
              "17      2     1.0\n",
              "18      2     1.0\n",
              "19      2     2.0\n",
              "20      0     0.0\n",
              "21      2     2.0\n",
              "22      0     0.0\n",
              "23      2     2.0\n",
              "24      2     2.0\n",
              "25      2     2.0\n",
              "26      2     2.0\n",
              "27      2     2.0\n",
              "28      0     0.0\n",
              "29      0     0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f11f5ee-1d2a-4e47-999f-5b92da80ccf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preds</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f11f5ee-1d2a-4e47-999f-5b92da80ccf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f11f5ee-1d2a-4e47-999f-5b92da80ccf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f11f5ee-1d2a-4e47-999f-5b92da80ccf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-00dbcce9-62e5-4e2e-9c1a-fa3fd5769d99\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-00dbcce9-62e5-4e2e-9c1a-fa3fd5769d99')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-00dbcce9-62e5-4e2e-9c1a-fa3fd5769d99 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"preds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0,\n          0.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LSzDKsBIzy-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
